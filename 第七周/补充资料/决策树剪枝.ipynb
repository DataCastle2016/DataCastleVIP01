{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树剪枝\n",
    "还记得决策树的构造过程吗？为了尽可能正确分类训练样本，节点的划分过程会不断重复直到不能再分，这样就可能对训练样本学习的“太好”了，把训练样本的一些特点当做所有数据都具有的一般性质，从而导致过拟合。这时就可以通过剪枝处理去掉一些分支来降低过拟合的风险。\n",
    "\n",
    "决策树的剪枝通常有两类方法，一类是预剪枝，另一类是后剪枝。预剪枝很好理解，就是在树的生长过程中就对其进行必要的剪枝，例如限制树生长的最大深度，即决策树的层数、限制决策树中间节点或叶节点中所包含的最小样本量以及限制决策树生成的最多叶节点数量等；后剪枝相对来说要复杂很多，它是指决策树在得到充分生长的前提下再对其返工修剪。\n",
    "\n",
    "预剪枝是在决策树的生成过程中，对每个结点划分前先做评估，如果划分不能提升决策树的泛化性能，就停止划分并将此节点记为叶节点；\n",
    "\n",
    "后剪枝是在决策树构造完成后，自底向上对非叶节点进行评估，如果将其换成叶节点能提升泛化性能，则将该子树换成叶节点。\n",
    "\n",
    "那么怎么判断泛化性能是否提升呢？这时需要将数据集分为训练集和验证集，利用训练集构造决策树，利用验证集来评估剪枝前后的验证集精度（即正确分类的比例）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7个后剪枝算法的所有python实现：https://github.com/appleyuchi/Decision_Tree_Prune\n",
    "\n",
    "剪枝算法和python实现的历史：https://blog.csdn.net/appleyuchi/article/details/83692381"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
